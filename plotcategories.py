import seaborn as sns
from matplotlib import pyplot as plt
from scipy.stats import beta as betadist
from scipy.stats import lognorm as lognormdist
from scipy.stats import norm as normdist
from numpy import divide, isnan, isinf, log, log10, ceil, append, multiply
from scipy.optimize import fminbound
import pandas as pd

plt.style.use("fivethirtyeight")

def __replacenaninf(col):
    col[isnan(col)]=0
    col[isinf(col)]=0
    return col


def plotConfidence(df, thresh=100, method=1, std=.05):
    """ df is a pandas DataFrame representing a particular category
        thresh is the end of the head
        method must equal 1, 2, 3 or 4
        
        method 1 is a single fitted beta
        method 2 is a beta fit on the head, with a separate beta fit on the tail
        method 3 is a beta fit on the tail, with the beta linearly transformed at a slope of (1/thresh) on the head
    """
    
    if method not in [1,2,3,4]: raise AttributeError("'method' parameter must equal 1, 2, 3, or 4")
    
    plt.figure(figsize=(6,2))
    
    M_k = len(df)
    s=[]
    
    ### Method 1: divide all c30's by a random value generated by the beta.
    ###
    ### cons: if high valued c30s limited by crawler (common in data as of 2016-11-10), 
    ###       the fit will be untrustworthy for high volume products, and therefore will miss low on predictions
    ### pros: simplest method.  Works in theory if c30 values are true (even for high volume products)

    if method==1:
        b = betadist.fit(df[df.ratio<1].ratio, floc=0, fscale=1)
        EVr_k = b[0]/(b[0]+b[1])   

        for i in range(5000):
            s.append(int(sum(divide(df.c30, betadist.rvs(b[0],b[1], 0,1, len(df))))))

    ### Method 2: divide all c30's by a random value generated by a beta_1 at the head, and beta_2 at the tail.
    ###
    ### cons: hard to choose a proper thresh.  
    ###       high variance for fitting on the head.
    ###       the fit will be untrustworthy for high volume products, and therefore will miss low on predictions
    ### pros: still simple.  Accounts for the obvious dip in ratio values for high volume products
    

    if method==2:
        b1 = betadist.fit(df[df.ratio<1].sort_values(by="q30",ascending=False).ratio[:thresh], floc=0, fscale=1)
        b2 = betadist.fit(df[df.ratio<1].sort_values(by="q30",ascending=False).ratio[thresh:], floc=0, fscale=1)
        EVr_k1 = b1[0]/(b1[0]+b1[1])   
        EVr_k2 = b2[0]/(b2[0]+b2[1])   

        for i in range(5000):
            s.append(int(sum(divide(df.c30.sort_values(ascending=False),
                                    append(betadist.rvs(b1[0],b1[1],0,1,thresh),
                                           betadist.rvs(b2[0],b2[1],0,1,M_k-thresh))))))

    ### Method 3: divide all c30's by a random value generated by beta*(x/thresh) at the head, and beta at the tail.
    ###
    ### cons: hard to choose a proper thresh.  
    ###       high variance for fitting on the head.
    ###       the fit will be untrustworthy for high volume products, and therefore will miss low on predictions
    ### pros: still simple.  Accounts for the obvious dip in ratio values for high volume products
    
    if method==3:
        b = betadist.fit(df[df.ratio<1].sort_values(by="q30", ascending=False).ratio[thresh:], floc=0, fscale=1)
        EVr_k = b[0]/(b[0]+b[1])   

        for i in range(5000):
            s.append(int(sum(divide(df.c30.sort_values(ascending=False),
                                    append(multiply([(1.0*x/thresh) for x in range(1,thresh+1)],
                                                    betadist.rvs(b[0],b[1],0,1,thresh)),
                                           betadist.rvs(b[0],b[1],0,1, M_k-thresh))))))

    ### Method 4: divide all c30's by a value generated using f, with some variance added to a.
    ###
    ### cons: hard to choose a proper thresh.  
    ###       high variance for fitting on the head.
    ###       the fit will be untrustworthy for high volume products, and therefore will miss low on predictions
    ### pros: still simple.  Accounts for the obvious dip in ratio values for high volume products
    
    if method==4:
        b = betadist.fit(df[df.ratio<1].sort_values(by="q30", ascending=False).ratio[thresh:], floc=0, fscale=1)
        EVr_k = b[0]/(b[0]+b[1])   

        def f(x,a): return a*x**((log(EVr_k) - log(a)) / log(M_k))
        def rss1(a):
            return sum((df.sort_values(by="q30", ascending=False).ratio - [f(j,a) for j in range(1,M_k+1)])**2)
        def rss2(a):
            return sum(divide((df.sort_values(by="q30", ascending=False).ratio - [f(j,a) for j in range(1,M_k+1)])**2,
                              range(1,M_k+1)))
        d_i = fminbound(rss2, 0, EVr_k)
        for i in range(1000):
            avals = normdist.rvs(d_i,std,M_k)
            avals[avals<.001] = d_i
            s.append(int(sum(divide(df.c30.sort_values(ascending=False), 
                                    [f(x, dd) for (x,dd) in zip(range(1, M_k+1),avals)]))))
    
    s = __replacenaninf(pd.Series(s))
    
    print "Estimates lower/upper bound: (%i,%i)"%(s.min(), s.max())
    
    totalq30 = df.q30.sum()

    ### upper bound of the histogram will frame the actual value in the exact middle of the plot
    upperboundpower = int(log10(totalq30))
    upperbound = 2*(ceil(totalq30/10**upperboundpower)*10**upperboundpower)
    
    plt.hist(s, bins=200, range=(0,upperbound), histtype="stepfilled")
    if method==2: plt.title("blue: $\sum q30$ estimate\t$EV[r]_{k1}:%.2f,EV[r]_{k2}:%.2f$"%(EVr_k1,EVr_k2))
    else:         plt.title("blue: $\sum q30$ estimate\t$EV[r]_k:%.2f$"%EVr_k)
    plt.plot([totalq30,totalq30],[0,100],"r:")
    plt.xlabel("red line: actual $\sum q30$\t$M_k:%5i$"%M_k)
    plt.yticks([])

    
def plot5Ests(dfs, startindex=0,zmin=1./10, zmax=2./10, guess=600, plotguess=False, plotest=False, kde=False, verbose=False):
    """ - dfs is a list of pandas DataFrames, each DataFrame represents a particular category.  
        - startindex will be where to start in dfs
    """
    
    plt.figure(figsize=(16,2))
    
    for i in range(startindex, startindex+5):
        M_k     = len(dfs[i])
        try:    
            ##Note: multiply guess here by 2 so that there's enough values to fit the beta onto
            if M_k>guess*2: b_i = betadist.fit(dfs[i].ratio[guess:], floc=0, fscale=1)
            else:           b_i = betadist.fit(dfs[i].ratio, floc=0, fscale=1)
        except: continue
        
        EV_i = b_i[0]/(b_i[0]+b_i[1])
        z1, z2  = int(M_k*zmin), int(M_k*zmax)
        
        def f(x,a): return a*x**((log(EV_i) - log(a)) / log(M_k))
                
        #if M_k>guess*2: 
        def rss1(a):
            return sum((dfs[i].sort_values(by="q30", ascending=False).ratio - [f(j,a) for j in range(1,M_k+1)])**2)
        def rss2(a):
            return sum(divide((dfs[i].sort_values(by="q30", ascending=False).ratio - [f(j,a) for j in range(1,M_k+1)])**2,range(1,M_k+1)))
        d_i = fminbound(rss2, 0, EV_i)
#            d_i = curve_fit(f, xdata = range(guess), ydata=dfs[i].sort_values(by="q30", ascending=False).ratio[:guess])
      #  else:           
       #     d_i = curve_fit(f1, xdata = range(M_k), ydata=dfs[i].sort_values(by="q30", ascending=False).ratio)

        plt.subplot(151+i-startindex)
        if kde==False:
            plt.scatter(range(z2), dfs[i].sort_values(by="q30", ascending=False).ratio.head(z2), alpha=.25); plt.ylim(0,1)
            plt.scatter(range(z1,M_k), dfs[i].sort_values(by="q30", ascending=False).ratio[z1:], color="red", alpha=.25)
        else: sns.kdeplot(pd.Series(range(M_k)), dfs[i].sort_values(by="q30", ascending=False).ratio, legend=False, shade_lowest=False, shade=True)

        plt.yticks([0,round(EV_i,2)]); plt.xlim(0,M_k)
        if plotest==True:   
#            if M_k>guess*2:
                plt.plot(range(M_k), [f(x, d_i) for x in range(M_k)], "y")
#                plot(range(guess,M_k), [EV_i for x in range(guess,M_k)], "y")
                plt.title("$M_{%i}$:%i\n a:%.3f"%(i,M_k,d_i))
                
                yest = divide(dfs[i].c30.sort_values(ascending=False), [f(x, d_i) for x in range(1, M_k+1)])
                yact = dfs[i].q30
                print "Estimated:%i, Actual:%i"%(round(sum(yest)),round(sum(yact))) 
                
                if verbose==True:
                    print "estimated: ",sum(yest), yest[:10]
                    print "actual: ",sum(yact), yact.sort_values(ascending=False)[:10]
                    print dfs[i].c30.sort_values(ascending=False)[:10]
                    print dfs[i].sort_values(by="q30",ascending=False).ratio[:10]
                plt.xlabel("%% error: %.1f"%(100*(sum(yest)-sum(yact))/sum(yact)))
#            else:
#                plot(range(M_k), [f1(x, d_i[0][0], d_i[0][1]) for x in range(M_k)], "y")
#                title("$M_k$:%i\n a:%.3f b:%.3f"%(M_k,d_i[0][0],d_i[0][1]))
        else:               plt.title("$M_k$:%i"%M_k)    
        if plotguess==True: plt.plot([guess,guess],[0,1]); plt.xticks([guess])
        else: plt.xticks([])
                
    